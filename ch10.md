### CMSC424 Reading Notes
#### Kaitlyn Yang | March 20, 2021

## Chapter 10: Storage and File Structure

- higher levels of implementing data models and languages
- characteristics of data structures
- alternative structures

### 10.1 Overview of Physical Storage Media

**primary storage**
- cache: fast but small
- main memory: data that can be operated on, still too small to store entire data base, content lost in power failure + system crashes
- flash memory: stored data can be retained when power is off, NAND (higher capcity, ex. cameras, music players, cell phones) and NOR, widely used for USBs
**secondary/online storage**
- magnetic-disk storage: for long-term online storage of data, can have entire database, non-volatile besides cases of self destruct
**tertiary/offline storage**
- optical storage: compact, CD or DVD, can be read only or write once read many
- tape storage: primarily backup and archival data

### 10.2 Magnetic Disk and Flash Storage

- disks are locally organized using a "redundant array of independent disks" (RAID)
- to measure the quality of a disk:
    - access time - time from when a read or write request is issued to when data transfer begins
    - seek time - time to reposition the arm, increases with the distance the arm needs to move
    - average seek time - average of seek times for random requests
    - rotational latency time - time spent waiting for a sector to be accessed
    - mean time to failure â€“ reliability of disk 

- optimally, successive block/page numbers in sequential access are easier to seek than random access which require a new seek every time
- for this reason, new methods to optimize were created:
    - buffering
    - read-ahead
    - scheduling
    - file organization - in ways we may expect data to be accessed
    - nonvolatile write buffers

### 10.3 RAID
- having a large number of disks allows to imrpove rate data can be read or written if operated in parallel
- imporves reliability of data bc redundant info can be stored on multiple disks (prevents data loss)

**Improvement of Reliability via Redundancy**
- the chance that at least one disk out of a set of N disks will fail is much higher than the chance that a specific single disk will fail
- to fix introduce redundancy by storing extra info to rebuild the lost data:
    - mirroring - most expensive, duplicate every disk, only fails if second disk fails before first disk is repaired
    - striping data - across multiple disks, easiest being bit level striping with an array of disk being treated as one large disk (bit i goes to disk i, etc.)
    - block level striping - stripes blocks across multiple disks, most commonly used

- goal:
1. load-balance multiple small acesses so throughput of access increases
2. parallelize large accesses so the response time is reduced

**RAID Levels**
- mirroring high reliability but expensive, striping has high data-transfer rates but does not improve reliability
- schemes of diff cost-performance trade-offs:

*levels*

0. nonredundant striping, striping at the level of blocks without any redundancy (no mirroring or parity bits), *high performance applications where data safety is not critical*
1. disk mirroring with block striping
2. memory-style error-correcting-code with parity bits which can be used to reconstruct damaged data, *rarely used because of level 3*
3. bit-interleaved parity organization, can detect if a sector has been read correctly with a single parity bit, as good as level 2 and less expensive, *inferior to level 5 in many ways with disk transfers*
4. block-interleaved parity organization with block-level striping, *rarely used because of level 5*
5. block-interleaved distributed parity, improves on 4 by parititioning across N+1 disks instead of storing data in N disks and parity in one disk, *lower overhead storage but high time overhead for writes, read frequently write rarely*
6. P+Q redundancy scheme, stores extra redundant information to guard multiple disk failures, can tolerate two disk failures, similar to level 5, *not supported in many cases*


### 10.5 File Organization
- a `file` is organized logically as a sequence of records mapped onto disk blocks
- logically partitioned into fixed-length storage units aka blocks

**fixed-length records**
- blocks aren't always perfectly placed with a record size
- a simple marker on a deleted record is not sufficient for locating and inserting, etc.
- at the beginning of the file allocate a certain number of bytes as a "file header", contains info abt the file: 
    - address of the first record whose contesnts are deleted
    - store address of second available record
    - pointers, creating a free list
    - on insertion, use record pointed to by the header before writing to end of file

**variable-length records**
- store multiple record types in a file, variable lengths for one or more fields, or allow repeating fields i.e. arrays
- use of a null bitmap where attributes of record have a null value (stored in 1 byte), alternatively null can be empty space or an offset
- slotted-page structure to organize records within a block:
    - header that includes # of record entries in the header, end of free space in block, array whose entries contain the location and size of each record
- records are allocated contiguously in the block starting from the end of the block
- if a record is inserted, space is allocated at end of free space and entry containing its size and location added to header
- if a record is deleted, space occupies is free and entry is set to "deleted" (i.e. size might be set to -1), records in the block before the deleted are moved, end-of-free-space pointer in header is updated

### 10.6 Organization of Records in Files
Several ways to organize:
- `Heap file organization`: any record can be placed anywhere in the file where there is space for record, no ordering, typically a single file for each relation
- `Sequential file organization`: records are stored in sequential ordered according to the value of a "search key"
- `Hashing file organization`: hash on some attribute of each record, result specifies which block of file the record should be placed in

**Sequential File Organization**
*allows for fast insertion of new records but may process records in an order that does not match physical record, especially as time passes*
- designed for efficient processing of records in sorted order based on some search key, any attribute or set (does not need to be primary key or even a superkey)
- chain together records by pointers
- to minimize number of block accesses, store records physically in search-key order or as close as possible
- difficult to maintain physical sequential order as records are inserted or deleted, costly to move many records

**Multitable Clustering File Organization**
*for larger databases*
- stores related reocrds of two or more relations in each block, allows reading records that satisfy a join condition on one block read
- depends on the types of queries the database designer believes to be most frequent

